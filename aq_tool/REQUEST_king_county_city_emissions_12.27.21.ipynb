{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### King County Request | December 2022\n",
    "\n",
    "\"Total onroad vehicle emissions and activity data within each jurisdiction's geographic boundary for the calendar years 2019 and 2020. If available, we would also request projections over time going to 2050. Only aggregate data is needed, broken down by the vehicle mode and fuel type, as shown in the table. If there is data that doesn't fit into the listed categories, please let us know.\"\n",
    "\n",
    "Requested for all King County cities, King County total and King County unicorporated areas.\n",
    "\n",
    "Years required include 2018, 2019, 2020, 2030, 2040, 2050. Interpolation between 2018 and 2030 are used to provide 2019 and 2020 estimates. \n",
    "\n",
    "\n",
    "A script was created to address the data request, which allows standard Soundcast network outputs to be segmented to the jurisdiction level. The \"aq_tool\" notebook processes Soundcast output for a list of provided cities and reports emissions and VMT by light, medium, and heavy vehicles. \n",
    "\n",
    "This notebook compiles and organizes the results of the aq_tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of output from aq_tool\n",
    "output_dir = r'C:\\Workspace\\aq_tool\\output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2018'\n",
    "df_18 = pd.read_csv(os.path.join(output_dir,year,year+'_summary.csv'), index_col='Unnamed: 0')\n",
    "\n",
    "year = '2030'\n",
    "df_30 = pd.read_csv(os.path.join(output_dir,year,year+'_summary.csv'), index_col='Unnamed: 0')\n",
    "\n",
    "year = '2040'\n",
    "df_40 = pd.read_csv(os.path.join(output_dir,year,year+'_summary.csv'), index_col='Unnamed: 0')\n",
    "\n",
    "year = '2050'\n",
    "df_50 = pd.read_csv(os.path.join(output_dir,year,year+'_summary.csv'), index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interpolations\n",
    "df = df_18.merge(df_30, on=['pollutant_name','city','veh_type'], suffixes=['_2018','_2030'], how='outer')\n",
    "\n",
    "# Merge 2040\n",
    "year = '2040'\n",
    "df = df.merge(df_40, on=['pollutant_name','city','veh_type'], how='outer')\n",
    "df.rename(columns={'total_daily_tons': 'total_daily_tons_'+year,\n",
    "                    'vmt': 'vmt_'+year}, inplace=True)\n",
    "\n",
    "# Merge 2050\n",
    "year = '2050'\n",
    "df = df.merge(df_50, on=['pollutant_name','city','veh_type'], how='outer')\n",
    "df.rename(columns={'total_daily_tons': 'total_daily_tons_'+year,\n",
    "                    'vmt': 'vmt_'+year}, inplace=True)\n",
    "\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(df, start_year, end_year, interpolated_year, var):\n",
    "    \"\"\"Interpolate values from two cols of data given start, end, and target (interpolated) years.\"\"\"\n",
    "    \n",
    "    # Calculate annual rate of change based on difference between values at start and end year, divided number of years difference\n",
    "    df['annual_'+var+'_change'] = (df[var+'_'+str(end_year)] - df[var+'_'+str(start_year)])/(end_year-start_year)\n",
    "    # Calculate \n",
    "    df[var+'_'+str(interpolated_year)] = df[var+'_'+str(start_year)]+df['annual_'+var+'_change']*(interpolated_year-start_year)\n",
    "\n",
    "    return df                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vmt = interpolate(df, 2018, 2030, 2019, 'vmt')\n",
    "df_vmt = interpolate(df, 2018, 2030, 2020, 'vmt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vmt = df_vmt[['city','pollutant_name','veh_type','vmt_2018','vmt_2019','vmt_2020','vmt_2030','vmt_2040','vmt_2050']]\n",
    "\n",
    "# VMT is duplicated for each pollutant total; Select only the first set of rows\n",
    "df_vmt = df_vmt.drop('pollutant_name', axis=1)\n",
    "df_vmt = df_vmt.groupby(['city','veh_type']).first()\n",
    "\n",
    "df_vmt.to_csv(r'C:\\Workspace\\aq_tool\\output\\king_county_cities_vmt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get county totals by vehicle type\n",
    "df_city_tot_vmt = df_vmt.groupby('veh_type').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emissions = interpolate(df, 2018, 2030, 2019, 'total_daily_tons')\n",
    "df_emissions = interpolate(df, 2018, 2030, 2020, 'total_daily_tons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emissions = df_emissions[['city','pollutant_name','veh_type','total_daily_tons_2018', 'total_daily_tons_2019',\n",
    "    'total_daily_tons_2020','total_daily_tons_2030','total_daily_tons_2040','total_daily_tons_2050']]\n",
    "df_emissions = df_emissions[df_emissions['pollutant_name'].isin(['Atmospheric CO2','CO2 Equivalent'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emissions.to_csv(r'C:\\Workspace\\aq_tool\\output\\king_county_cities_emissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get county totals by vehicle type\n",
    "df_city_tot_emissions = df_emissions.drop('city', axis=1).groupby(['pollutant_name','veh_type']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Totals for County and Unincorporated Areas\n",
    "\n",
    "Get county level results from the outputs of the regional results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_emissions(run_dir, county=None):\n",
    "    \n",
    "    # Get county level totals\n",
    "    df_interzonal = pd.read_csv(os.path.join(run_dir,r'outputs\\emissions\\interzonal_emissions.csv'))\n",
    "    df_intrazonal = pd.read_csv(os.path.join(run_dir,r'outputs\\emissions\\intrazonal_emissions.csv'))\n",
    "    start_emissions_df = pd.read_csv(os.path.join(r'outputs\\emissions\\start_emissions.csv'))\n",
    "    df_inter_group = df_interzonal.groupby(['pollutantID','veh_type','county']).sum()[['tons_tot','vmt']].reset_index()\n",
    "    df_inter_group.rename(columns={'tons_tot': 'interzonal_tons'}, inplace=True)\n",
    "    df_intra_group = df_intrazonal.groupby(['pollutantID','veh_type','county']).sum()[['tons_tot','vmt']].reset_index()\n",
    "    df_intra_group.rename(columns={'tons_tot': 'intrazonal_tons'}, inplace=True)\n",
    "    df_start_group = start_emissions_df.groupby(['pollutantID','veh_type','county']).sum()[['start_tons']].reset_index()\n",
    "\n",
    "    from emissions import finalize_emissions, pollutant_map\n",
    "    summary_df = pd.merge(df_inter_group, df_intra_group, on=['veh_type','pollutantID','county'], suffixes=['_interzonal','_intrazonal'])\n",
    "    summary_df['vmt'] = summary_df['vmt_interzonal']+summary_df['vmt_intrazonal']\n",
    "    summary_df = pd.merge(summary_df, df_start_group, how='left', on=['veh_type','pollutantID','county'])\n",
    "    # summary_df = finalize_emissions(summary_df, col_suffix=\"\")\n",
    "    pm10 = summary_df[summary_df['pollutantID'].isin([100,106,107])].groupby(['veh_type','county']).sum().reset_index()\n",
    "    pm10['pollutantID'] = 'PM10'\n",
    "    pm25 = summary_df[summary_df['pollutantID'].isin([110,116,117])].groupby(['veh_type','county']).sum().reset_index()\n",
    "    pm25['pollutantID'] = 'PM25'\n",
    "    summary_df = summary_df.append(pm10)\n",
    "    summary_df = summary_df.append(pm25)\n",
    "    summary_df.loc[~summary_df['pollutantID'].isin(['PM','PM10','PM25']),'pollutantID'] = summary_df[~summary_df['pollutantID'].isin(['PM','PM10','PM25'])]['pollutantID'].astype('int')\n",
    "    summary_df['pollutant_name'] = summary_df['pollutantID'].astype('int', errors='ignore').astype('str').map(pollutant_map)\n",
    "    summary_df['total_daily_tons'] = summary_df['start_tons']+summary_df['interzonal_tons']+summary_df['intrazonal_tons']\n",
    "    summary_df = summary_df[['pollutantID','county','pollutant_name','veh_type','start_tons','intrazonal_tons','interzonal_tons','total_daily_tons','vmt']]\n",
    "\n",
    "    # Filter for county\n",
    "    if county:\n",
    "        summary_df = summary_df[summary_df['county'] == county]\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = r'\\\\modelstation2\\c$\\Workspace\\sc_2018_rtp_final\\soundcast'\n",
    "df_18_county = get_county_emissions(run_dir, 'king')\n",
    "\n",
    "run_dir = r'\\\\modelstation1\\c$\\workspace\\sc_rtp_2030_final\\soundcast'\n",
    "df_30_county = get_county_emissions(run_dir, 'king')\n",
    "\n",
    "run_dir = r'\\\\modelstation1\\c$\\workspace\\sc_2040_rtp_final\\soundcast'\n",
    "df_40_county = get_county_emissions(run_dir, 'king')\n",
    "\n",
    "run_dir = r'\\\\modelstation1\\c$\\workspace\\sc_rtp_2050_constrained_final\\soundcast'\n",
    "df_50_county = get_county_emissions(run_dir, 'king')\n",
    "\n",
    "\n",
    "# Create interpolations\n",
    "df = df_18_county.merge(df_30_county, on=['pollutant_name','veh_type'], suffixes=['_2018','_2030'], how='outer')\n",
    "\n",
    "# Merge 2040\n",
    "year = '2040'\n",
    "df = df.merge(df_40_county, on=['pollutant_name','veh_type'], how='outer')\n",
    "df.rename(columns={'total_daily_tons': 'total_daily_tons_'+year,\n",
    "                    'vmt': 'vmt_'+year}, inplace=True)\n",
    "\n",
    "# # Merge 2050\n",
    "year = '2050'\n",
    "df = df.merge(df_50_county, on=['pollutant_name','veh_type'], how='outer')\n",
    "df.rename(columns={'total_daily_tons': 'total_daily_tons_'+year,\n",
    "                    'vmt': 'vmt_'+year}, inplace=True)\n",
    "\n",
    "\n",
    "df_vmt = interpolate(df, 2018, 2030, 2019, 'vmt')\n",
    "df_vmt = interpolate(df, 2018, 2030, 2020, 'vmt')\n",
    "df_vmt = df_vmt[['pollutant_name','veh_type','vmt_2018','vmt_2019','vmt_2020','vmt_2030','vmt_2040','vmt_2050']]\n",
    "\n",
    "df_emissions = interpolate(df, 2018, 2030, 2019, 'total_daily_tons')\n",
    "df_emissions = interpolate(df, 2018, 2030, 2020, 'total_daily_tons')\n",
    "df_emissions = df_emissions[['pollutant_name','veh_type','total_daily_tons_2018', 'total_daily_tons_2019',\n",
    "    'total_daily_tons_2020','total_daily_tons_2030','total_daily_tons_2040','total_daily_tons_2050']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emissions = df_emissions[df_emissions['pollutant_name'].isin(['Atmospheric CO2','CO2 Equivalent'])]\n",
    "df_emissions.to_csv(r'C:\\Workspace\\aq_tool\\output\\king_county_total_emissions.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_vmt = df_vmt.groupby('veh_type').first().reset_index()\n",
    "_df_vmt['geography'] = 'King County Total'\n",
    "_df_vmt.drop('pollutant_name', axis=1, inplace=True)\n",
    "_df_vmt.to_csv(r'C:\\Workspace\\aq_tool\\output\\king_county_total_vmt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df = df_city_tot_emissions.merge(df_emissions, suffixes=['_cities_tot','_county_tot'], on=['veh_type','pollutant_name'])\n",
    "for year in [2018,2019,2020,2030,2040,2050]:\n",
    "    df['total_daily_tons_unincorporated_'+str(year)] = df['total_daily_tons_'+str(year)+'_county_tot']-df['total_daily_tons_'+str(year)+'_cities_tot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['pollutant_name','veh_type']+['total_daily_tons_unincorporated_'+str(year) for year in ['2018',\n",
    "    '2019','2020','2030','2040','2050']]].to_csv(r'C:\\Workspace\\aq_tool\\output\\king_county_unincorporated_emissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_vmt.drop('geography', axis=1).merge(df_city_tot_vmt, suffixes=['_county','_city_total'], on='veh_type')\n",
    "# df = df_vmt.merge(df_emissions, suffixes=['_cities_tot','_county_tot'], on=['veh_type','pollutant_name'])\n",
    "for year in [2018,2019,2020,2030,2040,2050]:\n",
    "    df['vmt_unincorporated_'+str(year)] = df['vmt_'+str(year)+'_county']-df['vmt_'+str(year)+'_city_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geography'] = 'Unincorporated King'\n",
    "df[['veh_type','geography']+['vmt_unincorporated_'+str(year) for year in ['2018',\n",
    "    '2019','2020','2030','2040','2050']]].to_csv(r'C:\\Workspace\\aq_tool\\output\\king_county_unincorporated_vmt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a01578ef7fc98460838ddfd60bd3288ea700197594b0894c527f4f3349251842"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('summary': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
