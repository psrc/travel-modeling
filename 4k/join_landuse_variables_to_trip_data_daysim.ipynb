{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daysim formatted 2014 survey with adjusted weights\n",
    "trip = pd.read_csv(r'J:\\Projects\\Surveys\\HHTravel\\Survey2014\\Data\\Final database\\Release 4\\Adjusted\\trips_2014_adjusted_wt_daysim.csv')\n",
    "parcel = pd.read_csv(r'L:\\LODES\\soundcast_2014_lodes\\inputs\\buffered_parcels.txt', sep=' ')\n",
    "\n",
    "#export_trip_hh = pd.merge(export_trip_hh, parcel, left_on='opcl', right_on='parcelid')\n",
    "#export_trip_hh = pd.merge(export_trip_hh, parcel, left_on='dpcl', right_on='parcelid', suffixes=['_o','_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum employment variables by TAZ\n",
    "\n",
    "# Take a weighted average by emp, pop, and emp+pop for other variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate TAZ totals for households, employment\n",
    "totals_by_taz = parcel.groupby('taz_p').sum()[[\n",
    "       'hh_p', u'stugrd_p', u'stuhgh_p', u'stuuni_p', u'empedu_p',\n",
    "       u'empfoo_p', u'empgov_p', u'empind_p', u'empmed_p', u'empofc_p',\n",
    "       u'empret_p', u'empsvc_p', u'empoth_p', u'emptot_p']]\n",
    "totals_by_taz.columns = [i.split('_p')[0]+'_taz_tot' for i in totals_by_taz.columns]\n",
    "totals_by_taz = totals_by_taz.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'parcelid', u'xcoord_p', u'ycoord_p', u'sqft_p', u'taz_p', u'lutype_p',\n",
       "       u'hh_p', u'stugrd_p', u'stuhgh_p', u'stuuni_p', u'empedu_p',\n",
       "       u'empfoo_p', u'empgov_p', u'empind_p', u'empmed_p', u'empofc_p',\n",
       "       u'empret_p', u'empsvc_p', u'empoth_p', u'emptot_p', u'parkdy_p',\n",
       "       u'parkhr_p', u'ppricdyp', u'pprichrp', u'hh_1', u'stugrd_1',\n",
       "       u'stuhgh_1', u'stuuni_1', u'empedu_1', u'empfoo_1', u'empgov_1',\n",
       "       u'empind_1', u'empmed_1', u'empofc_1', u'empret_1', u'empsvc_1',\n",
       "       u'empoth_1', u'emptot_1', u'parkdy_1', u'parkhr_1', u'ppricdy1',\n",
       "       u'pprichr1', u'nodes1_1', u'nodes3_1', u'nodes4_1', u'tstops_1',\n",
       "       u'nparks_1', u'aparks_1', u'hh_2', u'stugrd_2', u'stuhgh_2',\n",
       "       u'stuuni_2', u'empedu_2', u'empfoo_2', u'empgov_2', u'empind_2',\n",
       "       u'empmed_2', u'empofc_2', u'empret_2', u'empsvc_2', u'empoth_2',\n",
       "       u'emptot_2', u'parkdy_2', u'parkhr_2', u'ppricdy2', u'pprichr2',\n",
       "       u'nodes1_2', u'nodes3_2', u'nodes4_2', u'tstops_2', u'nparks_2',\n",
       "       u'aparks_2', u'dist_lbus', u'dist_ebus', u'dist_crt', u'dist_fry',\n",
       "       u'dist_lrt', u'dist_park'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate a mixed use variable based on daysim calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate a weighted average for each TAZ\n",
    "# based on the parcel buffers\n",
    "# This avoids bias based on TAZ boundaries\n",
    "\n",
    "# Weighted by parcel population, parcel employment, and combination of both\n",
    "# For 1st buffer (0.25 miles?)\n",
    "\n",
    "wt_fields = ['stugrd_',\n",
    "       u'stuhgh_', u'stuuni_', u'empedu_', u'empfoo_', u'empgov_',\n",
    "       u'empind_', u'empmed_', u'empofc_', u'empret_', u'empsvc_',\n",
    "       u'empoth_', u'emptot_', u'parkdy_', u'parkhr_', u'ppricdy',\n",
    "       u'pprichr','tstops_']\n",
    "\n",
    "transit_fields = ['dist_lbus', u'dist_ebus', u'dist_crt', u'dist_fry', u'dist_lrt', u'dist_park']\n",
    "\n",
    "for field in wt_fields:\n",
    "    \n",
    "    # Get numerator of weights (values within buffered areas)\n",
    "    # to be divided by denominator of total hh/emp/hh+emp\n",
    "    \n",
    "    # Weight by parcel population, for 0.25 and 0.5 mile buffers\n",
    "    parcel[field+'hh_wt1_tot'] = parcel[field+'1']*parcel['hh_p']    # .25 mile\n",
    "    parcel[field+'hh_wt2_tot'] = parcel[field+'2']*parcel['hh_p']    # .5 mile\n",
    "    \n",
    "    # Weight by total parcel employment\n",
    "    parcel[field+'emp_wt1_tot'] = parcel[field+'1']*parcel['emptot_p']    # .25 mile\n",
    "    parcel[field+'emp_wt2_tot'] = parcel[field+'2']*parcel['emptot_p']    # .5 mile\n",
    "    \n",
    "    # Weight by households + employment\n",
    "    parcel[field+'hhemp_wt1_tot'] = parcel[field+'1']*(parcel['emptot_p']+parcel['hh_p'])# .25 mile\n",
    "    parcel[field+'hhemp_wt2_tot'] = parcel[field+'2']*(parcel['emptot_p']+parcel['hh_p'])# .5 mile\n",
    "\n",
    "for field in transit_fields:\n",
    "    \n",
    "    parcel[field+'_hh_wt_tot'] = parcel[field]*parcel['hh_p']\n",
    "    parcel[field+'_emp_wt_tot'] = parcel[field]*parcel['emptot_p']\n",
    "    parcel[field+'_hhemp_wt_tot'] = parcel[field]*(parcel['emptot_p']+parcel['hh_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stugrd_\n",
      "stuhgh_\n",
      "stuuni_\n",
      "empedu_\n",
      "empfoo_\n",
      "empgov_\n",
      "empind_\n",
      "empmed_\n",
      "empofc_\n",
      "empret_\n",
      "empsvc_\n",
      "empoth_\n",
      "emptot_\n",
      "parkdy_\n",
      "parkhr_\n",
      "ppricdy\n",
      "pprichr\n",
      "tstops_\n"
     ]
    }
   ],
   "source": [
    "# Compute weighted average for TAZ based on \n",
    "\n",
    "parcel['emptot_plus_hh'] = parcel['emptot_p']+parcel['hh_p']\n",
    "\n",
    "for field in wt_fields:\n",
    "    print field\n",
    "    # Weights based on household size\n",
    "    totals_by_taz[field+'hh_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'hh_wt1_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    totals_by_taz[field+'hh_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'hh_wt2_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    \n",
    "    # Weights based on employment\n",
    "    totals_by_taz[field+'emp_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'emp_wt1_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    totals_by_taz[field+'emp_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'emp_wt2_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    \n",
    "    # weights based on housheholds + employment\n",
    "    totals_by_taz[field+'hhemp_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'hhemp_wt1_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']\n",
    "    totals_by_taz[field+'hhemp_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'hhemp_wt2_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']\n",
    "    \n",
    "for field in transit_fields:\n",
    "    totals_by_taz[field+'_hh_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_hh_wt_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    totals_by_taz[field+'_emp_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_emp_wt_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    totals_by_taz[field+'_hhemp_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_hhemp_wt_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NaNs with zeros - for zones with 0 hh or emp, divide by 0 results in NaN\n",
    "totals_by_taz = totals_by_taz.fillna(0)\n",
    "\n",
    "# Join totals by taz to the trip file\n",
    "trip = pd.read_csv(r'J:\\Projects\\Surveys\\HHTravel\\Survey2014\\Data\\Final database\\Release 4\\Adjusted\\trips_2014_adjusted_wt_daysim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclude trips to or from external zones\n",
    "trip = trip[trip['otaz'] != 0]\n",
    "trip = trip[trip['dtaz'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(trip, totals_by_taz, left_on='otaz', right_on='taz_p', how='left')\n",
    "df = pd.merge(df, totals_by_taz, left_on='dtaz', right_on='taz_p', how='left', suffixes=['_o','_d'])\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join transit access mode to data to split transit mode into walk and auto-access\n",
    "tour = pd.read_csv(r'R:\\SoundCastDocuments\\2014Estimation\\Files_From_Mark_2014\\new_weights_10_28_16\\skims_attached\\tourP14.dat',\n",
    "                   delim_whitespace=True)\n",
    "\n",
    "df = pd.merge(df, tour[['hhno','pno','day','tour','tmodetp']], on=['hhno','pno','day','tour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'R:\\4K\\2014\\Trip Generation\\Trip Rates\\2014-new-adjusted\\trip_2014_adjusted_lu_vars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhno</th>\n",
       "      <th>pno</th>\n",
       "      <th>day</th>\n",
       "      <th>tour</th>\n",
       "      <th>half</th>\n",
       "      <th>tseg</th>\n",
       "      <th>tsvid</th>\n",
       "      <th>opurp</th>\n",
       "      <th>dpurp</th>\n",
       "      <th>oadtyp</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_fry_hh_wt_avg_d</th>\n",
       "      <th>dist_fry_emp_wt_avg_d</th>\n",
       "      <th>dist_fry_hhemp_wt_avg_d</th>\n",
       "      <th>dist_lrt_hh_wt_avg_d</th>\n",
       "      <th>dist_lrt_emp_wt_avg_d</th>\n",
       "      <th>dist_lrt_hhemp_wt_avg_d</th>\n",
       "      <th>dist_park_hh_wt_avg_d</th>\n",
       "      <th>dist_park_emp_wt_avg_d</th>\n",
       "      <th>dist_park_hhemp_wt_avg_d</th>\n",
       "      <th>tmodetp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income_crossclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>...</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "      <td>7637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>...</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "      <td>12479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>...</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "      <td>7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>...</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "      <td>17906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hhno    pno    day   tour   half   tseg  tsvid  opurp  \\\n",
       "income_crossclass                                                           \n",
       "1                   7637   7637   7637   7637   7637   7637   7637   7637   \n",
       "2                  12479  12479  12479  12479  12479  12479  12479  12479   \n",
       "3                   7590   7590   7590   7590   7590   7590   7590   7590   \n",
       "4                  17906  17906  17906  17906  17906  17906  17906  17906   \n",
       "\n",
       "                   dpurp  oadtyp   ...     dist_fry_hh_wt_avg_d  \\\n",
       "income_crossclass                  ...                            \n",
       "1                   7637    7637   ...                     7637   \n",
       "2                  12479   12479   ...                    12479   \n",
       "3                   7590    7590   ...                     7590   \n",
       "4                  17906   17906   ...                    17906   \n",
       "\n",
       "                   dist_fry_emp_wt_avg_d  dist_fry_hhemp_wt_avg_d  \\\n",
       "income_crossclass                                                   \n",
       "1                                   7637                     7637   \n",
       "2                                  12479                    12479   \n",
       "3                                   7590                     7590   \n",
       "4                                  17906                    17906   \n",
       "\n",
       "                   dist_lrt_hh_wt_avg_d  dist_lrt_emp_wt_avg_d  \\\n",
       "income_crossclass                                                \n",
       "1                                  7637                   7637   \n",
       "2                                 12479                  12479   \n",
       "3                                  7590                   7590   \n",
       "4                                 17906                  17906   \n",
       "\n",
       "                   dist_lrt_hhemp_wt_avg_d  dist_park_hh_wt_avg_d  \\\n",
       "income_crossclass                                                   \n",
       "1                                     7637                   7637   \n",
       "2                                    12479                  12479   \n",
       "3                                     7590                   7590   \n",
       "4                                    17906                  17906   \n",
       "\n",
       "                   dist_park_emp_wt_avg_d  dist_park_hhemp_wt_avg_d  tmodetp  \n",
       "income_crossclass                                                             \n",
       "1                                    7637                      7637     7637  \n",
       "2                                   12479                     12479    12479  \n",
       "3                                    7590                      7590     7590  \n",
       "4                                   17906                     17906    17906  \n",
       "\n",
       "[4 rows x 325 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('income_crossclass').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
