{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Daysim formatted 2014 survey with adjusted weights\n",
    "trip = pd.read_excel(r'R:\\4K\\2014\\Trip Generation\\Trip Rates\\2014-new-adjusted\\trip_2014_survey_adjusted_daysim.xlsx')\n",
    "parcel = pd.read_csv(r'Q:\\soundcast_2014\\inputs\\buffered_parcels.txt', sep=' ')\n",
    "\n",
    "#export_trip_hh = pd.merge(export_trip_hh, parcel, left_on='opcl', right_on='parcelid')\n",
    "#export_trip_hh = pd.merge(export_trip_hh, parcel, left_on='dpcl', right_on='parcelid', suffixes=['_o','_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum employment variables by TAZ\n",
    "\n",
    "# Take a weighted average by emp, pop, and emp+pop for other variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate TAZ totals for households, employment\n",
    "totals_by_taz = parcel.groupby('taz_p').sum()[[\n",
    "       'hh_p', u'stugrd_p', u'stuhgh_p', u'stuuni_p', u'empedu_p',\n",
    "       u'empfoo_p', u'empgov_p', u'empind_p', u'empmed_p', u'empofc_p',\n",
    "       u'empret_p', u'empsvc_p', u'empoth_p', u'emptot_p']]\n",
    "totals_by_taz.columns = [i.split('_p')[0]+'_taz_tot' for i in totals_by_taz.columns]\n",
    "totals_by_taz = totals_by_taz.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcualte the mixed use variable on parcel data\n",
    "# using daysim definition from Log2 functino\n",
    "parcel['tot_hhemp_1'] = parcel['emptot_1'] + parcel['hh_1']\n",
    "parcel['tot_hhemp_2'] = parcel['emptot_2'] + parcel['hh_2']\n",
    "\n",
    "parcel['mixed_use_1'] = -1*(((parcel['emptot_1']/parcel['tot_hhemp_1'])*np.log(parcel['emptot_1']/parcel['tot_hhemp_1']) \\\n",
    "+ (parcel['hh_1']/parcel['tot_hhemp_1'])*np.log(parcel['hh_1']/parcel['tot_hhemp_1']))/np.log(2))\n",
    "\n",
    "parcel['mixed_use_2'] = -1*(((parcel['emptot_2']/parcel['tot_hhemp_2'])*np.log(parcel['emptot_2']/parcel['tot_hhemp_2']) \\\n",
    "+ (parcel['hh_2']/parcel['tot_hhemp_2'])*np.log(parcel['hh_2']/parcel['tot_hhemp_2']))/np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate a weighted average for each TAZ\n",
    "# based on the parcel buffers\n",
    "# This avoids bias based on TAZ boundaries\n",
    "\n",
    "# Weighted by parcel population, parcel employment, and combination of both\n",
    "# For 1st buffer (0.25 miles?)\n",
    "\n",
    "wt_fields = ['stugrd_', 'hh_',\n",
    "       u'stuhgh_', u'stuuni_', u'empedu_', u'empfoo_', u'empgov_',\n",
    "       u'empind_', u'empmed_', u'empofc_', u'empret_', u'empsvc_',\n",
    "       u'empoth_', u'emptot_', u'parkdy_', u'parkhr_', u'ppricdy',\n",
    "       u'pprichr','tstops_','mixed_use_']\n",
    "\n",
    "transit_fields = ['dist_lbus', u'dist_ebus', u'dist_crt', u'dist_fry', u'dist_lrt', u'dist_park']\n",
    "\n",
    "for field in wt_fields:\n",
    "    \n",
    "    # Get numerator of weights (values within buffered areas)\n",
    "    # to be divided by denominator of total hh/emp/hh+emp\n",
    "    \n",
    "    # Weight by parcel population, for 0.25 and 0.5 mile buffers\n",
    "    parcel[field+'hh_wt1_tot'] = parcel[field+'1']*parcel['hh_p']    # .25 mile\n",
    "    parcel[field+'hh_wt2_tot'] = parcel[field+'2']*parcel['hh_p']    # .5 mile\n",
    "    \n",
    "    # Weight by total parcel employment\n",
    "    parcel[field+'emp_wt1_tot'] = parcel[field+'1']*parcel['emptot_p']    # .25 mile\n",
    "    parcel[field+'emp_wt2_tot'] = parcel[field+'2']*parcel['emptot_p']    # .5 mile\n",
    "    \n",
    "    # Weight by households + employment\n",
    "    parcel[field+'hhemp_wt1_tot'] = parcel[field+'1']*(parcel['emptot_p']+parcel['hh_p'])# .25 mile\n",
    "    parcel[field+'hhemp_wt2_tot'] = parcel[field+'2']*(parcel['emptot_p']+parcel['hh_p'])# .5 mile\n",
    "\n",
    "for field in transit_fields:\n",
    "    \n",
    "    parcel[field+'_hh_wt_tot'] = parcel[field]*parcel['hh_p']\n",
    "    parcel[field+'_emp_wt_tot'] = parcel[field]*parcel['emptot_p']\n",
    "    parcel[field+'_hhemp_wt_tot'] = parcel[field]*(parcel['emptot_p']+parcel['hh_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stugrd_\n",
      "hh_\n",
      "stuhgh_\n",
      "stuuni_\n",
      "empedu_\n",
      "empfoo_\n",
      "empgov_\n",
      "empind_\n",
      "empmed_\n",
      "empofc_\n",
      "empret_\n",
      "empsvc_\n",
      "empoth_\n",
      "emptot_\n",
      "parkdy_\n",
      "parkhr_\n",
      "ppricdy\n",
      "pprichr\n",
      "tstops_\n",
      "mixed_use_\n"
     ]
    }
   ],
   "source": [
    "# Compute weighted average for TAZ based on \n",
    "\n",
    "parcel['emptot_plus_hh'] = parcel['emptot_p']+parcel['hh_p']\n",
    "\n",
    "for field in wt_fields:\n",
    "    print field\n",
    "    # Weights based on household size\n",
    "    totals_by_taz[field+'hh_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'hh_wt1_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    totals_by_taz[field+'hh_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'hh_wt2_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    \n",
    "    # Weights based on employment\n",
    "    totals_by_taz[field+'emp_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'emp_wt1_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    totals_by_taz[field+'emp_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'emp_wt2_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    \n",
    "    # weights based on housheholds + employment\n",
    "    totals_by_taz[field+'hhemp_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'hhemp_wt1_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']\n",
    "    totals_by_taz[field+'hhemp_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'hhemp_wt2_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']\n",
    "    \n",
    "for field in transit_fields:\n",
    "    totals_by_taz[field+'_hh_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_hh_wt_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    totals_by_taz[field+'_emp_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_emp_wt_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    totals_by_taz[field+'_hhemp_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_hhemp_wt_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NaNs with zeros - for zones with 0 hh or emp, divide by 0 results in NaN\n",
    "totals_by_taz = totals_by_taz.fillna(0)\n",
    "\n",
    "# Join totals by taz to the trip file\n",
    "trip = pd.read_excel(r'R:\\4K\\2014\\Trip Generation\\Trip Rates\\2014-new-adjusted\\trip_2014_survey_adjusted_daysim.xlsx')\n",
    "# trip = pd.read_csv(r'J:\\Projects\\Surveys\\HHTravel\\Survey2014\\Data\\Final database\\Release 4\\Adjusted\\trips_2014_adjusted_wt_daysim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write TAZ totals to file\n",
    "totals_by_taz.to_csv(r'R:\\4K\\2014\\Trip Generation\\Trip Rates\\2014-new-adjusted\\4k_2014_taz_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclude trips to or from external zones\n",
    "trip = trip[trip['otaz'] != 0]\n",
    "trip = trip[trip['dtaz'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(trip, totals_by_taz, left_on='otaz', right_on='taz_p', how='left')\n",
    "df = pd.merge(df, totals_by_taz, left_on='dtaz', right_on='taz_p', how='left', suffixes=['_o','_d'])\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join transit access mode to data to split transit mode into walk and auto-access\n",
    "tour = pd.read_csv(r'R:\\SoundCastDocuments\\2014Estimation\\Files_From_Mark_2014\\new_weights_10_28_16\\skims_attached\\tourP14.dat',\n",
    "                   delim_whitespace=True)\n",
    "\n",
    "df = pd.merge(df, tour[['hhno','pno','day','tour','tmodetp']], on=['hhno','pno','day','tour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'R:\\4K\\2014\\Trip Generation\\Trip Rates\\2014-new-adjusted\\trip_2014_adjusted_lu_vars_daysim.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         770.630597\n",
       "1         872.866342\n",
       "2        2082.066967\n",
       "3        2082.066967\n",
       "4         593.976919\n",
       "5        2082.066967\n",
       "6        1270.330933\n",
       "7        2082.066967\n",
       "8         720.596986\n",
       "9        2082.066967\n",
       "10        720.596986\n",
       "11       2082.066967\n",
       "12          0.000000\n",
       "13       2545.428413\n",
       "14       2675.414779\n",
       "15       3545.072811\n",
       "16       3545.072811\n",
       "17       3545.072811\n",
       "18       3545.072811\n",
       "19       2545.428413\n",
       "20       2675.414779\n",
       "21       4504.563965\n",
       "22       3473.618015\n",
       "23       5968.881247\n",
       "24        230.247400\n",
       "25       5968.881247\n",
       "26          0.000000\n",
       "27          0.000000\n",
       "28       1616.981250\n",
       "29          0.000000\n",
       "            ...     \n",
       "45582     560.464175\n",
       "45583      78.626192\n",
       "45584     280.040496\n",
       "45585     225.182650\n",
       "45586     505.310601\n",
       "45587      35.500530\n",
       "45588     280.040496\n",
       "45589     700.526351\n",
       "45590     958.491807\n",
       "45591      35.090765\n",
       "45592     700.526351\n",
       "45593     958.491807\n",
       "45594      35.090765\n",
       "45595     700.526351\n",
       "45596     958.491807\n",
       "45597      35.090765\n",
       "45598       0.000000\n",
       "45599       0.000000\n",
       "45600       0.000000\n",
       "45601       0.000000\n",
       "45602    1015.153238\n",
       "45603     207.615448\n",
       "45604       0.000000\n",
       "45605       0.000000\n",
       "45606    2729.573730\n",
       "45607       0.000000\n",
       "45608    1748.560117\n",
       "45609    2027.026855\n",
       "45610     474.176848\n",
       "45611       0.000000\n",
       "Name: hh_hh_wt1_avg_d, Length: 45612, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hh_hh_wt1_avg_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
