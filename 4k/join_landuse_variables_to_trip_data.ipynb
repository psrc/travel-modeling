{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Daysim formatted 2014 survey with adjusted weights\n",
    "trip = pd.read_csv(r'J:\\Projects\\Surveys\\HHTravel\\Survey2014\\Data\\Final database\\Release 4\\Adjusted\\trips_2014_adjusted_wt_daysim.csv')\n",
    "parcel = pd.read_csv(r'L:\\LODES\\soundcast_2014_lodes\\inputs\\buffered_parcels.txt', sep=' ')\n",
    "\n",
    "#export_trip_hh = pd.merge(export_trip_hh, parcel, left_on='opcl', right_on='parcelid')\n",
    "#export_trip_hh = pd.merge(export_trip_hh, parcel, left_on='dpcl', right_on='parcelid', suffixes=['_o','_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum employment variables by TAZ\n",
    "\n",
    "# Take a weighted average by emp, pop, and emp+pop for other variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate TAZ totals for households, employment\n",
    "totals_by_taz = parcel.groupby('taz_p').sum()[[\n",
    "       'hh_p', u'stugrd_p', u'stuhgh_p', u'stuuni_p', u'empedu_p',\n",
    "       u'empfoo_p', u'empgov_p', u'empind_p', u'empmed_p', u'empofc_p',\n",
    "       u'empret_p', u'empsvc_p', u'empoth_p', u'emptot_p']]\n",
    "totals_by_taz.columns = [i.split('_p')[0]+'_taz_tot' for i in totals_by_taz.columns]\n",
    "totals_by_taz = totals_by_taz.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'parcelid', u'xcoord_p', u'ycoord_p', u'sqft_p', u'taz_p', u'lutype_p',\n",
       "       u'hh_p', u'stugrd_p', u'stuhgh_p', u'stuuni_p', u'empedu_p',\n",
       "       u'empfoo_p', u'empgov_p', u'empind_p', u'empmed_p', u'empofc_p',\n",
       "       u'empret_p', u'empsvc_p', u'empoth_p', u'emptot_p', u'parkdy_p',\n",
       "       u'parkhr_p', u'ppricdyp', u'pprichrp', u'hh_1', u'stugrd_1',\n",
       "       u'stuhgh_1', u'stuuni_1', u'empedu_1', u'empfoo_1', u'empgov_1',\n",
       "       u'empind_1', u'empmed_1', u'empofc_1', u'empret_1', u'empsvc_1',\n",
       "       u'empoth_1', u'emptot_1', u'parkdy_1', u'parkhr_1', u'ppricdy1',\n",
       "       u'pprichr1', u'nodes1_1', u'nodes3_1', u'nodes4_1', u'tstops_1',\n",
       "       u'nparks_1', u'aparks_1', u'hh_2', u'stugrd_2', u'stuhgh_2',\n",
       "       u'stuuni_2', u'empedu_2', u'empfoo_2', u'empgov_2', u'empind_2',\n",
       "       u'empmed_2', u'empofc_2', u'empret_2', u'empsvc_2', u'empoth_2',\n",
       "       u'emptot_2', u'parkdy_2', u'parkhr_2', u'ppricdy2', u'pprichr2',\n",
       "       u'nodes1_2', u'nodes3_2', u'nodes4_2', u'tstops_2', u'nparks_2',\n",
       "       u'aparks_2', u'dist_lbus', u'dist_ebus', u'dist_crt', u'dist_fry',\n",
       "       u'dist_lrt', u'dist_park'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate a weighted average for each TAZ\n",
    "# based on the parcel buffers\n",
    "# This avoids bias based on TAZ boundaries\n",
    "\n",
    "# Weighted by parcel population, parcel employment, and combination of both\n",
    "# For 1st buffer (0.25 miles?)\n",
    "\n",
    "wt_fields = ['stugrd_',\n",
    "       u'stuhgh_', u'stuuni_', u'empedu_', u'empfoo_', u'empgov_',\n",
    "       u'empind_', u'empmed_', u'empofc_', u'empret_', u'empsvc_',\n",
    "       u'empoth_', u'emptot_', u'parkdy_', u'parkhr_', u'ppricdy',\n",
    "       u'pprichr','tstops_']\n",
    "\n",
    "transit_fields = ['dist_lbus', u'dist_ebus', u'dist_crt', u'dist_fry', u'dist_lrt', u'dist_park']\n",
    "\n",
    "for field in wt_fields:\n",
    "    \n",
    "    # Get numerator of weights (values within buffered areas)\n",
    "    # to be divided by denominator of total hh/emp/hh+emp\n",
    "    \n",
    "    # Weight by parcel population, for 0.25 and 0.5 mile buffers\n",
    "    parcel[field+'hh_wt1_tot'] = parcel[field+'1']*parcel['hh_p']    # .25 mile\n",
    "    parcel[field+'hh_wt2_tot'] = parcel[field+'2']*parcel['hh_p']    # .5 mile\n",
    "    \n",
    "    # Weight by total parcel employment\n",
    "    parcel[field+'emp_wt1_tot'] = parcel[field+'1']*parcel['emptot_p']    # .25 mile\n",
    "    parcel[field+'emp_wt2_tot'] = parcel[field+'2']*parcel['emptot_p']    # .5 mile\n",
    "    \n",
    "    # Weight by households + employment\n",
    "    parcel[field+'hhemp_wt1_tot'] = parcel[field+'1']*(parcel['emptot_p']+parcel['hh_p'])# .25 mile\n",
    "    parcel[field+'hhemp_wt2_tot'] = parcel[field+'2']*(parcel['emptot_p']+parcel['hh_p'])# .5 mile\n",
    "\n",
    "for field in transit_fields:\n",
    "    \n",
    "    parcel[field+'_hh_wt_tot'] = parcel[field]*parcel['hh_p']\n",
    "    parcel[field+'_emp_wt_tot'] = parcel[field]*parcel['emptot_p']\n",
    "    parcel[field+'_hhemp_wt_tot'] = parcel[field]*(parcel['emptot_p']+parcel['hh_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stugrd_\n",
      "stuhgh_\n",
      "stuuni_\n",
      "empedu_\n",
      "empfoo_\n",
      "empgov_\n",
      "empind_\n",
      "empmed_\n",
      "empofc_\n",
      "empret_\n",
      "empsvc_\n",
      "empoth_\n",
      "emptot_\n",
      "parkdy_\n",
      "parkhr_\n",
      "ppricdy\n",
      "pprichr\n",
      "tstops_\n"
     ]
    }
   ],
   "source": [
    "# Compute weighted average for TAZ based on \n",
    "\n",
    "parcel['emptot_plus_hh'] = parcel['emptot_p']+parcel['hh_p']\n",
    "\n",
    "for field in wt_fields:\n",
    "    print field\n",
    "    # Weights based on household size\n",
    "    totals_by_taz[field+'hh_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'hh_wt1_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    totals_by_taz[field+'hh_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'hh_wt2_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    \n",
    "    # Weights based on employment\n",
    "    totals_by_taz[field+'emp_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'emp_wt1_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    totals_by_taz[field+'emp_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'emp_wt2_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    \n",
    "    # weights based on housheholds + employment\n",
    "    totals_by_taz[field+'hhemp_wt1_avg'] = parcel.groupby('taz_p').sum()[field+'hhemp_wt1_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']\n",
    "    totals_by_taz[field+'hhemp_wt2_avg'] = parcel.groupby('taz_p').sum()[field+'hhemp_wt2_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']\n",
    "    \n",
    "for field in transit_fields:\n",
    "    totals_by_taz[field+'_hh_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_hh_wt_tot']/parcel.groupby('taz_p').sum()['hh_p']\n",
    "    totals_by_taz[field+'_emp_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_emp_wt_tot']/parcel.groupby('taz_p').sum()['emptot_p']\n",
    "    totals_by_taz[field+'_hhemp_wt_avg'] = parcel.groupby('taz_p').sum()[field+'_hhemp_wt_tot']/parcel.groupby('taz_p').sum()['emptot_plus_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NaNs with zeros - for zones with 0 hh or emp, divide by 0 results in NaN\n",
    "totals_by_taz = totals_by_taz.fillna(0)\n",
    "\n",
    "# Join totals by taz to the trip file\n",
    "trip = pd.read_csv(r'J:\\Projects\\Surveys\\HHTravel\\Survey2014\\Data\\Final database\\Release 4\\Adjusted\\trips_2014_adjusted_wt_daysim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude trips to or from external zones\n",
    "trip = trip[trip['otaz'] != 0]\n",
    "trip = trip[trip['dtaz'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(trip, totals_by_taz, left_on='otaz', right_on='taz_p', how='left')\n",
    "df = pd.merge(df, totals_by_taz, left_on='dtaz', right_on='taz_p', how='left', suffixes=['_o','_d'])\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join transit access mode to data to split transit mode into walk and auto-access\n",
    "tour = pd.read_csv(r'R:\\SoundCastDocuments\\2014Estimation\\Files_From_Mark_2014\\new_weights_10_28_16\\skims_attached\\tourP14.dat',\n",
    "                   delim_whitespace=True)\n",
    "\n",
    "df = pd.merge(df, tour[['hhno','pno','day','tour','tmodetp']], on=['hhno','pno','day','tour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'R:\\4K\\2014\\Trip Generation\\Trip Rates\\2014-new-adjusted\\trip_2014_adjusted_lu_vars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
