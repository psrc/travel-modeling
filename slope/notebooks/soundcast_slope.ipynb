{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import archook\n",
    "\n",
    "# Use archook to import arcpy\n",
    "archook.get_arcpy()\n",
    "import arcpy\n",
    "from arcpy.sa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplope Calculations for Bike Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Input Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Emme network shapefile location\n",
    "emme_shapefile = r'R:\\SoundCast\\Inputs\\2014\\networks\\edges_0.shp'\n",
    "\n",
    "output_dir = r'R:\\Bike\\slope\\soundcast'\n",
    "\n",
    "# Create a geodatabase for working with data\n",
    "geodb = r'soundcast_slope.gdb'\n",
    "arcpy.env.workspace = os.path.join(output_dir, geodb)\n",
    "\n",
    "# name of Emme network shapefile, after exported to geodatabase\n",
    "in_fc = geodb + r'\\edges_0'\n",
    "\n",
    "# Elevation raster location\n",
    "in_raster = r'W:\\geodata\\raster\\dem30m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'R:\\\\Bike\\\\slope\\\\soundcast\\\\soundcast_slope.gdb'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new geodatabase\n",
    "arcpy.CreateFileGDB_management(output_dir, geodb)\n",
    "\n",
    "# Add soundcast network shapefile to feature class\n",
    "arcpy.FeatureClassToGeodatabase_conversion(emme_shapefile, os.path.join(output_dir,geodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'R:\\\\Bike\\\\slope\\\\soundcast\\\\soundcast_slope.gdb\\\\edges_0'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = os.path.join(output_dir,geodb)\n",
    "\n",
    "# Add field to the feature class, concatentating the inode and jnode for a unique ID\n",
    "arcpy.AddField_management('edges_0', 'ID', \"TEXT\")\n",
    "\n",
    "arcpy.CalculateField_management('edges_0', 'ID', \"str(!NewINode!)+'-'+str(!NewJNode!)\",'PYTHON_9.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find two-way links - we only need to split these links once\n",
    "emme_links = arcpy.da.FeatureClassToNumPyArray(os.path.join(output_dir,in_fc), ('ID','Shape_Length','NewINode','NewJNode'))\n",
    "df = pd.DataFrame(emme_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change geodatabase field names to match more generic Emme shapefile network output format\n",
    "\n",
    "# Convert shape_length to miles\n",
    "df['LENGTH'] = df['Shape_Length']/5280\n",
    "df.rename(columns={'NewINode': 'INODE', 'NewJNode': 'JNODE'}, inplace=True)\n",
    "df.drop('Shape_Length',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18449"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare this network versus existing slope attributes\n",
    "# Only process on the subset that don't have slope already attached\n",
    "old_attr = pd.read_csv(r'R:\\SoundCast\\Inputs\\2014\\bikes\\emme_attr.in',sep=' ')\n",
    "old_attr['ID'] = old_attr['inode'].astype('str')+'-'+old_attr['jnode'].astype('str')\n",
    "\n",
    "# List of link IDs from imported network not in current attr file\n",
    "len(df[-df['ID'].isin(old_attr['ID'].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop through each link \n",
    "ij_links = []\n",
    "ji_links = []\n",
    "\n",
    "for rownum in xrange(len(df)):\n",
    "    inode = df.iloc[rownum].INODE\n",
    "    jnode = df.iloc[rownum].JNODE\n",
    "    ij_df = df[(df['INODE']==inode)&(df['JNODE']==jnode)]\n",
    "    if len(ij_df) == 1:\n",
    "        ij_id = ij_df.ID.values[0]\n",
    "    \n",
    "    ji_df = df[(df['INODE']==jnode)&(df['JNODE']==inode)]\n",
    "    if len(ji_df) == 1:\n",
    "        ji_id = ji_df.ID.values[0]\n",
    "    else:\n",
    "        # indicates a one-way link with no ji\n",
    "        # append to ij_links and skip to next\n",
    "        ij_links.append(ij_id)\n",
    "        continue\n",
    "    \n",
    "    if ji_id not in ij_links:\n",
    "        ij_links.append(ij_id)\n",
    "    else:\n",
    "        ji_links.append(ij_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ij_df = df[df['ID'].isin(ij_links)]\n",
    "ji_df = df[df['ID'].isin(ji_links)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ij_df)+len(ji_df)==len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- export results to feature class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split network lines into points\n",
    "- note: this takes 30-60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- should only have to do this one time\n",
    "- subsequent buffering will compare the imported shapefile links to the result of the cold-start process and only work on the links that haven't been processed yet, appending them to the existing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through each network link and split the line into points, saving them in points array\n",
    "points = []\n",
    "sr = arcpy.Describe(os.path.join(output_dir,in_fc)).spatialReference\n",
    "counter = 0\n",
    "id_field = 'ID'   \n",
    "\n",
    "# Set the step based on the line's length\n",
    "# How many times must the line be split\n",
    "# \n",
    "# Using 30 of fidelity - data is available every 30 meters so this may be unnecessary\n",
    "segment_len = 30\n",
    "\n",
    "# Create seperate array that holds tuple of link ID and point coordinates (in state plane coords)\n",
    "final_result = []\n",
    "count = 0\n",
    "with arcpy.da.SearchCursor(os.path.join(output_dir,in_fc),[\"SHAPE@\",id_field], spatial_reference=sr) as cursor:  \n",
    "    for row in cursor:\n",
    "        # Only process IJ links, because JI are exactly the same polyline shape\n",
    "        if row[1] in ij_links:\n",
    "            count += 1\n",
    "            split_count = int(row[0].length/segment_len)\n",
    "            big_output = []\n",
    "            for i in range(split_count):\n",
    "                point = row[0].positionAlongLine(i*segment_len)\n",
    "                points.append(point)\n",
    "                x = point.firstPoint.X\n",
    "                y = point.firstPoint.Y\n",
    "                point_list = []\n",
    "                point_list.append(x)\n",
    "                point_list.append(y)\n",
    "                output = (str(row[1]), (x, y))\n",
    "                final_result.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Export results to a feature class called link_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'R:\\\\Bike\\\\slope\\\\soundcast\\\\soundcast_slope.gdb\\\\link_components'>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_out_new = r'link_components'\n",
    "# arcpy.CopyFeatures_management(points, r\"R:\\Bike\\slope\\bkr\\bkr_sample.gdb\" + point_out_new)\n",
    "# delete_fc = True\n",
    "# if delete_fc:\n",
    "#     arcpy.DeleteFeatures_management(r\"R:\\Bike\\slope\\bkr\\bkr_network.gdb\" + point_out_new)\n",
    "arcpy.CopyFeatures_management(points, os.path.join(output_dir,geodb,point_out_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R:\\\\Bike\\\\slope\\\\soundcast\\\\soundcast_slope.gdb\\\\link_components'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(output_dir,geodb,point_out_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intersect the points with the links to get the edge IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'R:\\\\Bike\\\\slope\\\\soundcast\\\\soundcast_slope.gdb\\\\link_components_full'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inFeatures = [\"link_components\", \"edges_0\"]\n",
    "intersectOutput = \"link_components_full\"\n",
    "clusterTolerance = 1.5    \n",
    "arcpy.Intersect_analysis(inFeatures, intersectOutput, \"\", clusterTolerance, \"point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intersect with a raster to get elevation\n",
    "- import elevation raster from W:/geodata/raster/dem30m\n",
    "    - this is the raster of elevations at 30 m fidelity\n",
    "    - note that elevation values are in METERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that spatial analyst must be active for this portion\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "# arcpy.env.workspace = r'R:\\Bike\\slope\\bkr\\bkr_network.gdb'\n",
    "\n",
    "in_point_features = r'link_components_full'\n",
    "out_point_features = r'link_components_elevation'\n",
    "ExtractValuesToPoints(in_point_features, in_raster, out_point_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read resulting intersection of points with elevation into numpy/pandas\n",
    "elevation_shp = arcpy.da.FeatureClassToNumPyArray(out_point_features, ('RASTERVALU','ID','NewINode','NewJNode'))\n",
    "df = pd.DataFrame(elevation_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of links IDs\n",
    "link_list = df.groupby('ID').min().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through all edges\n",
    "# Assume that all links are bi-directional and compute ij and ji direction slopes\n",
    "# if a line is truly one-way, we will discard the ji direction\n",
    "# since most are two-way it's worth it calculate for all links and merge results later\n",
    "upslope_ij = {}\n",
    "upslope_ji = {}\n",
    "for link in link_list: \n",
    "    link_df = df[df['ID'] == link]\n",
    "\n",
    "    # Extract the elevation data to numPy because it's faster to loop over\n",
    "    elev_data = link_df['RASTERVALU'].values\n",
    "\n",
    "    # Loop through each point in each edge\n",
    "    upslope_ij[link] = 0\n",
    "    upslope_ji[link] = 0\n",
    "    for point in xrange(len(elev_data)-1):  # stop short of the list because we only want to compare the 2nd to last to last\n",
    "        elev_diff = elev_data[point+1] - elev_data[point]\n",
    "        if elev_diff > 0:\n",
    "            upslope_ij[link] += elev_diff\n",
    "        elif elev_diff < 0:\n",
    "            upslope_ji[link] += abs(elev_diff)      # since we know it will be \"negative\" for the JI direction when calculated\n",
    "                                                    # in references to the IJ direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import dictionary to a series and attach upslope back on the original dataframe\n",
    "upslope_ij_s = pd.Series(upslope_ij, name='elev_gain_ij')\n",
    "upslope_ji_s = pd.Series(upslope_ji, name='elev_gain_ji')\n",
    "upslope_ij_s.index.name='ID'\n",
    "upslope_ij_s = upslope_ij_s.reset_index()\n",
    "upslope_ji_s.index.name='ID'\n",
    "upslope_ji_s = upslope_ji_s.reset_index()\n",
    "\n",
    "# Attach ij-direction slope to IJ links\n",
    "slope_ij = pd.merge(ij_df,upslope_ij_s,on='ID')\n",
    "slope_ij.rename(columns={\"elev_gain_ij\": \"elev_gain\"}, inplace=True)\n",
    "\n",
    "# Attach ji-direction slope to JI links\n",
    "\n",
    "# fo JI links, flip the i and j values to get lookup of ji links\n",
    "upslope_ji_s['newID'] = upslope_ji_s.ID.apply(lambda row: row.split('-')[-1]+\"-\"+row.split('-')[0])\n",
    "slope_ji = pd.merge(ji_df,upslope_ji_s,left_on='ID',right_on='newID')\n",
    "slope_ji.rename(columns={\"elev_gain_ji\": \"elev_gain\"}, inplace=True)\n",
    "slope_ji['ID'] = slope_ji['newID']\n",
    "slope_ji.drop(['ID_x','ID_y','newID'],axis=1,inplace=True)\n",
    "\n",
    "# Append ji rows to ij to get a complete list of links\n",
    "slope_df = slope_ij.append(slope_ji)\n",
    "\n",
    "# Convert elevation into feet from meters\n",
    "slope_df['elev_gain'] = slope_df['elev_gain']*3.28084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calcualte the average upslope in feet/feet\n",
    "# Network distance measured in: miles, elevation in meters \n",
    "slope_df['avg_upslope'] = slope_df['elev_gain']/(slope_df['LENGTH']*5280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reformat and export as emme_attr.in\n",
    "- for BKR, assume all bike facilities are 0 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emme_attr = slope_df\n",
    "emme_attr.rename(columns={'INODE':'inode','JNODE':'jnode','avg_upslope':'@upslp'},\n",
    "                inplace=True)\n",
    "\n",
    "emme_attr.drop(['LENGTH','elev_gain'], axis=1, inplace=True)\n",
    "\n",
    "# add bike facility of 0\n",
    "# emme_attr['@bkfac'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- some very short links are not processed\n",
    "- assume zero elevation change for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of IDs from network not included in the final outpu\n",
    "df = pd.DataFrame(emme_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34224\n",
      "34271\n"
     ]
    }
   ],
   "source": [
    "print len(emme_attr)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_links = df[-df['ID'].isin(emme_attr['ID'].values)]\n",
    "missing_links = missing_links[['ID','NewINode','NewJNode']]\n",
    "missing_links.columns = [i.lower() for i in missing_links.columns] \n",
    "\n",
    "missing_links['@upslp'] = 0\n",
    "missing_links['@bkfac'] = 0\n",
    "\n",
    "emme_attr = emme_attr.append(missing_links)\n",
    "\n",
    "emme_attr.drop(['id','ID'], axis=1,inplace=True)\n",
    "emme_attr = emme_attr[['inode','jnode','@bkfac','@upslp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add bike facility links\n",
    "# NOTE: bike attributes table was manually added to working database from geodatabase\n",
    "# seems there is not a good way of doing this automatically based on latest review of ESRI policy\n",
    "bike_attr = geodb + r'\\tblBikeAttributes'\n",
    "bike_df = pd.DataFrame(arcpy.da.TableToNumPyArray(os.path.join(output_dir, bike_attr), \n",
    "                                     ('PSRCEdgeID','JIBikeFacil','IJBikeFacil'),\n",
    "                                    null_value=-9999))\n",
    "\n",
    "bike_df = bike_df[bike_df['PSRCEdgeID'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look up the ij ID from PSRC Edge ID\n",
    "# Find two-way links - we only need to split these links once\n",
    "emme_links =pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(os.path.join(output_dir,in_fc), ('ID','PSRCEdgeID','NewINode','NewJNode')))\n",
    "bike_df = pd.merge(emme_links,bike_df,how='left',on='PSRCEdgeID')\n",
    "\n",
    "# bike_df has 2-way links, we want a table for each direction\n",
    "bike_ij = bike_df[['NewINode','NewJNode','IJBikeFacil']]\n",
    "bike_ij.rename(columns={'IJBikeFacil':'BikeFacil'},inplace=True)\n",
    "\n",
    "bike_ji = bike_df[['NewINode','NewJNode','JIBikeFacil']]\n",
    "bike_ji.rename(columns={'JIBikeFacil':'BikeFacil','NewINode':'NewJNode','NewJNode':'NewINode'},inplace=True)\n",
    "\n",
    "bike_df = bike_ij.append(bike_ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now merge bike_df with emme_attr based on inode and jnode\n",
    "emme_attr = pd.merge(emme_attr, bike_df, how='left', left_on=['inode','jnode'], right_on=['NewINode','NewJNode']).drop_duplicates()\n",
    "emme_attr['@bkfac'] = emme_attr['BikeFacil']\n",
    "emme_attr = emme_attr[['inode','jnode','@bkfac','@upslp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that all ferry links do not have significant upslope (mode='fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export emme transaction file\n",
    "emme_attr.to_csv(output_dir + r'\\emme_attr.in', sep=' ', index=False)\n",
    "\n",
    "# Export version for use in ArcMap\n",
    "# emme_attr['id']=emme_attr['inode'].astype('str')+'-'+emme_attr['jnode'].astype('str')\n",
    "# emme_attr.to_csv(output_dir + r'\\emme_attr.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the soundcast results for comparison\n",
    "df = pd.read_csv(r'R:\\SoundCast\\Inputs\\2014\\bikes\\emme_attr.in', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.3756189894\n",
      "0.0332534048304\n",
      "0.0192160023467\n"
     ]
    }
   ],
   "source": [
    "print df['@upslp'].max()\n",
    "print df['@upslp'].mean()\n",
    "print df['@upslp'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.41235999936\n",
      "0.025638120134\n",
      "0.0102561332173\n"
     ]
    }
   ],
   "source": [
    "print emme_attr['@upslp'].max()\n",
    "print emme_attr['@upslp'].mean()\n",
    "print emme_attr['@upslp'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
