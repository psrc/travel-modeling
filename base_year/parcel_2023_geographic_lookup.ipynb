{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Modeller\\AppData\\Local\\anaconda3\\envs\\summary\\lib\\site-packages\\geopandas\\_compat.py:115: UserWarning: The Shapely GEOS version (3.11.4-CAPI-1.17.4) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import psrcelmerpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_year = '2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get geographic lookup categories for reference\n",
    "df_cols = pd.read_csv(r'R:\\e2projects_two\\SoundCast\\Inputs\\db_inputs\\parcel_2023_geography.csv')\n",
    "\n",
    "# Load parcel geodata\n",
    "# df_parcel = gpd.read_file(r'R:\\e2projects_two\\2023_base_year\\all_streets\\2023_parcels\\inputs\\parcels_2023.csv')\n",
    "# df_parcel['PARCEL_ID'] = df_parcel['PARCEL_ID'].apply(lambda x: x.split('.')[0]).astype('int64')\n",
    "\n",
    "df_parcel = pd.read_csv(r'R:\\e2projects_two\\SoundCast\\Inputs\\dev\\landuse\\2023\\23_on_23_v2\\parcels_urbansim.txt',\n",
    "                         sep='\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aparks</th>\n",
       "      <th>empedu_p</th>\n",
       "      <th>empfoo_p</th>\n",
       "      <th>empgov_p</th>\n",
       "      <th>empind_p</th>\n",
       "      <th>empmed_p</th>\n",
       "      <th>empofc_p</th>\n",
       "      <th>empoth_p</th>\n",
       "      <th>empret_p</th>\n",
       "      <th>emprsc_p</th>\n",
       "      <th>...</th>\n",
       "      <th>ppricdyp</th>\n",
       "      <th>pprichrp</th>\n",
       "      <th>sfunits</th>\n",
       "      <th>sqft_p</th>\n",
       "      <th>stugrd_p</th>\n",
       "      <th>stuhgh_p</th>\n",
       "      <th>stuuni_p</th>\n",
       "      <th>taz_p</th>\n",
       "      <th>xcoord_p</th>\n",
       "      <th>ycoord_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85802.593750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "      <td>1.292255e+06</td>\n",
       "      <td>162728.617255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>1.291832e+06</td>\n",
       "      <td>164041.742835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000.066365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>1.291595e+06</td>\n",
       "      <td>164048.669737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7200.084044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>1.291540e+06</td>\n",
       "      <td>164050.178628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6068.041674</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>1.291479e+06</td>\n",
       "      <td>164042.397388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aparks  empedu_p  empfoo_p  empgov_p  empind_p  empmed_p  empofc_p  \\\n",
       "0       0         0         0         0         0         0         0   \n",
       "1       0         0         0         0         0         0         0   \n",
       "2       0         0         0         0         0         0         2   \n",
       "3       0         0         0         0         2         0         0   \n",
       "4       0         0         0         0         0         0         0   \n",
       "\n",
       "   empoth_p  empret_p  emprsc_p  ...  ppricdyp  pprichrp  sfunits  \\\n",
       "0         0         0         0  ...         0         0        0   \n",
       "1         0         0         0  ...         0         0        0   \n",
       "2         0         0         0  ...         0         0        0   \n",
       "3         2         2         0  ...         0         0        0   \n",
       "4         0         0         0  ...         0         0        0   \n",
       "\n",
       "         sqft_p  stugrd_p  stuhgh_p  stuuni_p  taz_p      xcoord_p  \\\n",
       "0  85802.593750         0         0         0   1019  1.292255e+06   \n",
       "1      0.000000         0         0         0   1018  1.291832e+06   \n",
       "2   6000.066365         0         0         0   1018  1.291595e+06   \n",
       "3   7200.084044         0         0         0   1018  1.291540e+06   \n",
       "4   6068.041674         0         0         0   1018  1.291479e+06   \n",
       "\n",
       "        ycoord_p  \n",
       "0  162728.617255  \n",
       "1  164041.742835  \n",
       "2  164048.669737  \n",
       "3  164050.178628  \n",
       "4  164042.397388  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel_full = gpd.GeoDataFrame(\n",
    "    df_parcel, geometry=gpd.points_from_xy(df_parcel.xcoord_p, df_parcel.ycoord_p), crs=\"EPSG:2285\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel = gdf_parcel_full[['parcelid', 'geometry']]\n",
    "\n",
    "# FIXME: use a small gdf for testing\n",
    "# gdf_parcel = gdf_parcel.iloc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_layer(eg_conn, layer_name, col_list=None):\n",
    "    gdf = eg_conn.read_geolayer(layer_name)\n",
    "    if col_list:\n",
    "        gdf = gdf[col_list]\n",
    "    gdf = gdf.to_crs('EPSG:2285')\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Census layers\n",
    "eg_conn = psrcelmerpy.ElmerGeoConn()\n",
    "for layer_name, geoid_field in {\n",
    "    # 'block2010': 'geoid10',\n",
    "    'block2020': 'geoid20'}.items():\n",
    "    gdf = load_layer(eg_conn, layer_name, [geoid_field,'geometry'])\n",
    "    gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "    gdf_parcel.drop(columns=['index_right'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the block group and tract from the geoid\n",
    "# gdf_parcel['Census2010BlockGroup'] = gdf_parcel['geoid10'].astype('str').apply(lambda x: x[0:12])\n",
    "# gdf_parcel['Census2010Tract'] = gdf_parcel['geoid10'].astype('str').apply(lambda x: x[0:11])\n",
    "# gdf_parcel['Census2010Block'] = gdf_parcel['geoid10'].copy()\n",
    "gdf_parcel['Census2020BlockGroup'] = gdf_parcel['geoid20'].astype('str').apply(lambda x: x[0:12])\n",
    "gdf_parcel['Census2020Tract'] = gdf_parcel['geoid20'].astype('str').apply(lambda x: x[0:11])\n",
    "gdf_parcel['Census2020Block'] = gdf_parcel['geoid20'].copy()\n",
    "\n",
    "gdf_parcel.rename(columns={\n",
    "    # 'geoid10': 'GEOID10', \n",
    "    'geoid20': 'GEOID20'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_parcel.head()\n",
    "# eg_conn.read_geolayer(layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with regional geography\n",
    "gdf = load_layer(eg_conn, 'regional_geographies', ['class_desc','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'class_desc': 'rg_proposed'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with city boundaries\n",
    "gdf = load_layer(eg_conn, 'cities', ['city_name','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'city_name': 'CityName'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with county boundaries\n",
    "gdf = load_layer(eg_conn, 'county_background', ['county_nm','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'county_nm': 'CountyName'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329928"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf_parcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with FAZ\n",
    "# gdf = load_layer(eg_conn, 'faz_2010', ['faz10','geometry'])\n",
    "# gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "# gdf_parcel.rename(columns={'faz10': 'FAZID'}, inplace=True)\n",
    "# gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "# Merge with TAZ\n",
    "gdf = load_layer(eg_conn, 'taz2010', ['taz','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'taz': 'taz_p'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "gdf_parcel['TAZ'] = gdf_parcel['taz_p'].copy()\n",
    "\n",
    "# district\n",
    "gdf = load_layer(eg_conn, 'soundcast_taz_districts', ['district','new_distri','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'district': 'District', 'new_distri': 'district_name'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "# regional growth centers\n",
    "gdf = load_layer(eg_conn, 'urban_centers', ['name','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'name': 'GrowthCenterName'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census place\n",
    "# gdf = load_layer(eg_conn, 'place2010', ['name10','geometry'])\n",
    "# gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "# gdf_parcel.rename(columns={'name10': 'place_name_2010'}, inplace=True)\n",
    "# gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "gdf = load_layer(eg_conn, 'place2020', ['name','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'name': 'place_name_2020'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use Elmer tables to get the equity geography data\n",
    "# Note that 2023 is not yet available\n",
    "# FIXME: update to use 2023 census defintions when available\n",
    "e_conn = psrcelmerpy.ElmerConn()\n",
    "df_equity = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.racial_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>equity_geog_vs_50_percent</th>\n",
       "      <th>equity_geog_vs_reg_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53033000101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53033000102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53033000201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53033000202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53033000300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         geoid  equity_geog_vs_50_percent  equity_geog_vs_reg_total\n",
       "0  53033000101                          1                         1\n",
       "1  53033000102                          0                         0\n",
       "2  53033000201                          0                         1\n",
       "3  53033000202                          1                         1\n",
       "4  53033000300                          0                         0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_equity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_equity = pd.DataFrame()\n",
    "\n",
    "# See this for reference http://aws-linux/mediawiki/index.php/Equity_Geographies_in_Elmer\n",
    "df_equity = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.racial_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df_equity.rename(columns={'equity_geog_vs_50_percent': 'racial_geog_vs_50_percent',\n",
    "                          'equity_geog_vs_reg_total': 'racial_geog_vs_reg_total'},\n",
    "                          inplace=True)\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.disability_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'disability_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'disability_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.elderly_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'elderly_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'elderly_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.limited_english_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'english_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'english_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.poverty_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'poverty_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'poverty_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.youth_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'youth_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'youth_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to geodataframe\n",
    "# Note, per ACS the geography should correspond with the latest data in ACS 3- or 5-year data (or the given year of 1-year ACS).\n",
    "# This means we will use 2020 geography for 5-year ACS data from 2017-2022, which is listed as 2022 data in Elmer for the tract equity data \n",
    "# https://www.census.gov/programs-surveys/acs/geography-acs/geography-boundaries-by-year.2022.html\n",
    "\n",
    "# join to geodataframe basedon tract\n",
    "if int(equity_data_year) >= 2020:\n",
    "    gdf_col = 'Census2020Tract'\n",
    "else:\n",
    "    gdf_col = 'Census2010Tract'\n",
    "\n",
    "gdf_parcel = gdf_parcel.merge(df_equity, left_on=gdf_col, right_on='geoid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "gdf_parcel.rename(columns={'PARCEL_ID': 'ParcelID'}, inplace=True)\n",
    "gdf_parcel['BaseYear'] = 2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifically label parcels outside of RGCs\n",
    "gdf_parcel['GrowthCenterName'] = gdf_parcel['GrowthCenterName'].fillna('Not in RGC')\n",
    "\n",
    "# Rename parcel ID to match convention\n",
    "gdf_parcel.rename(columns={'parcelid': 'ParcelID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename counties that are outside the region\n",
    "gdf_parcel.loc[~gdf_parcel['CountyName'].isin(['King','Kitsap','Pierce','Snohomish']), 'CountyName'] = 'Outside Region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HCT station data provided by Craig\n",
    "gdf_stops = gpd.read_file(r'R:\\e2projects_two\\2023_base_year\\network\\transit_stops.shp')\n",
    "gdf_stops.rename(columns={'all_day': 'all_day_transit',\n",
    "                          'frequent': 'frequent_transit'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>frequent_transit</th>\n",
       "      <th>all_day_transit</th>\n",
       "      <th>min_routes</th>\n",
       "      <th>hct</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ct_1</td>\n",
       "      <td>Marine Dr NE &amp; 27th Ave NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1308628.035 388068.676, 1308626.226 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ct_7</td>\n",
       "      <td>Marine Dr NE &amp; 23rd Ave NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1307297.752 387728.165, 1307295.943 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ct_12</td>\n",
       "      <td>Totem Beach Rd &amp; Tulalip Bay Dr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1288816.444 390279.579, 1288814.635 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ct_13</td>\n",
       "      <td>Totem Beach Rd &amp; 70th St NW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1289288.480 389692.453, 1289286.671 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ct_18</td>\n",
       "      <td>Marine Dr NE &amp; 19th Ave NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1306231.570 387167.052, 1306229.761 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stop_id                        stop_name  frequent_transit  all_day_transit  \\\n",
       "0    ct_1       Marine Dr NE & 27th Ave NE               0.0              0.0   \n",
       "1    ct_7       Marine Dr NE & 23rd Ave NE               0.0              0.0   \n",
       "2   ct_12  Totem Beach Rd & Tulalip Bay Dr               0.0              0.0   \n",
       "3   ct_13      Totem Beach Rd & 70th St NW               0.0              0.0   \n",
       "4   ct_18       Marine Dr NE & 19th Ave NE               0.0              0.0   \n",
       "\n",
       "   min_routes  hct                                           geometry  \n",
       "0         0.0  0.0  POLYGON ((1308628.035 388068.676, 1308626.226 ...  \n",
       "1         0.0  0.0  POLYGON ((1307297.752 387728.165, 1307295.943 ...  \n",
       "2         0.0  0.0  POLYGON ((1288816.444 390279.579, 1288814.635 ...  \n",
       "3         0.0  0.0  POLYGON ((1289288.480 389692.453, 1289286.671 ...  \n",
       "4         0.0  0.0  POLYGON ((1306231.570 387167.052, 1306229.761 ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all_day = gdf_stops[gdf_stops['all_day_transit']==1][['all_day_transit','geometry']]\n",
    "gdf_frequent = gdf_stops[gdf_stops['frequent_transit']==1][['frequent_transit','geometry']]\n",
    "gdf_hct = gdf_stops[gdf_stops['hct']==1][['hct','geometry']]\n",
    "\n",
    "# Merge spatially join each to parcel data\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf_all_day, how=\"left\")\n",
    "gdf_parcel.drop('index_right', axis=1, inplace=True)\n",
    "gdf_parcel['all_day_transit'].fillna(0, inplace=True)\n",
    "\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf_frequent, how=\"left\")\n",
    "gdf_parcel.drop('index_right', axis=1, inplace=True)\n",
    "gdf_parcel['frequent_transit'].fillna(0, inplace=True)\n",
    "\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf_hct, how=\"left\")\n",
    "gdf_parcel.drop('index_right', axis=1, inplace=True)\n",
    "gdf_parcel['hct'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some fields as integers\n",
    "col_list = ['taz_p','TAZ','District','racial_geog_vs_50_percent', 'racial_geog_vs_reg_total',\n",
    "       'disability_geog_vs_50_percent', 'disability_geog_vs_reg_total',\n",
    "       'elderly_geog_vs_50_percent', 'elderly_geog_vs_reg_total',\n",
    "       'english_geog_vs_50_percent', 'english_geog_vs_reg_total',\n",
    "       'poverty_geog_vs_50_percent', 'poverty_geog_vs_reg_total',\n",
    "       'youth_geog_vs_50_percent', 'youth_geog_vs_reg_total',\n",
    "       'all_day_transit','frequent_transit','hct']\n",
    "gdf_parcel[col_list] = gdf_parcel[col_list].fillna(-1).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel = gdf_parcel.drop('geometry', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel.to_csv(r'C:\\Workspace\\parcel_2023_geography.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_parcel.to_csv(r'R:\\e2projects_two\\SoundCast\\Inputs\\db_inputs\\parcel_2023_geography.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_parcel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_parcel['CountyName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cols.columns[~df_cols.columns.isin(gdf_parcel.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
