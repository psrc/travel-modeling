{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Modeller\\AppData\\Local\\anaconda3\\envs\\summary\\lib\\site-packages\\geopandas\\_compat.py:115: UserWarning: The Shapely GEOS version (3.11.4-CAPI-1.17.4) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import psrcelmerpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_year = '2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parcel geodata\n",
    "df_parcel = pd.read_csv(r'R:\\e2projects_two\\SoundCast\\Inputs\\dev\\landuse\\2023\\23_on_23_v3\\parcels_urbansim.txt',\n",
    "                         sep='\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329928"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_parcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel_full = gpd.GeoDataFrame(\n",
    "    df_parcel, geometry=gpd.points_from_xy(df_parcel.xcoord_p, df_parcel.ycoord_p), crs=\"EPSG:2285\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel = gdf_parcel_full[['parcelid', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_layer(eg_conn, layer_name, col_list=None):\n",
    "    gdf = eg_conn.read_geolayer(layer_name)\n",
    "    if col_list:\n",
    "        gdf = gdf[col_list]\n",
    "    gdf = gdf.to_crs('EPSG:2285')\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Census layers\n",
    "eg_conn = psrcelmerpy.ElmerGeoConn()\n",
    "for layer_name, geoid_field in {\n",
    "    # 'block2010': 'geoid10',\n",
    "    'block2020': 'geoid20'}.items():\n",
    "    gdf = load_layer(eg_conn, layer_name, [geoid_field,'geometry'])\n",
    "    gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "    gdf_parcel.drop(columns=['index_right'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the block group and tract from the geoid\n",
    "# gdf_parcel['Census2010BlockGroup'] = gdf_parcel['geoid10'].astype('str').apply(lambda x: x[0:12])\n",
    "# gdf_parcel['Census2010Tract'] = gdf_parcel['geoid10'].astype('str').apply(lambda x: x[0:11])\n",
    "# gdf_parcel['Census2010Block'] = gdf_parcel['geoid10'].copy()\n",
    "gdf_parcel['Census2020BlockGroup'] = gdf_parcel['geoid20'].astype('str').apply(lambda x: x[0:12])\n",
    "gdf_parcel['Census2020Tract'] = gdf_parcel['geoid20'].astype('str').apply(lambda x: x[0:11])\n",
    "gdf_parcel['Census2020Block'] = gdf_parcel['geoid20'].copy()\n",
    "\n",
    "gdf_parcel.rename(columns={\n",
    "    # 'geoid10': 'GEOID10', \n",
    "    'geoid20': 'GEOID20'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with regional geography\n",
    "gdf = load_layer(eg_conn, 'regional_geographies', ['class_desc','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'class_desc': 'rg_proposed'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with city boundaries\n",
    "gdf = load_layer(eg_conn, 'cities', ['city_name','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'city_name': 'CityName'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with county boundaries\n",
    "gdf = load_layer(eg_conn, 'county_background', ['county_nm','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'county_nm': 'CountyName'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329928"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf_parcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with FAZ\n",
    "# gdf = load_layer(eg_conn, 'faz_2010', ['faz10','geometry'])\n",
    "# gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "# gdf_parcel.rename(columns={'faz10': 'FAZID'}, inplace=True)\n",
    "# gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "# Merge with TAZ\n",
    "gdf = load_layer(eg_conn, 'taz2010', ['taz','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'taz': 'taz_p'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "gdf_parcel['TAZ'] = gdf_parcel['taz_p'].copy()\n",
    "\n",
    "# district\n",
    "gdf = load_layer(eg_conn, 'soundcast_taz_districts', ['district','new_distri','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'district': 'District', 'new_distri': 'district_name'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "# regional growth centers\n",
    "gdf = load_layer(eg_conn, 'urban_centers', ['name','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'name': 'GrowthCenterName'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census place\n",
    "# gdf = load_layer(eg_conn, 'place2010', ['name10','geometry'])\n",
    "# gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "# gdf_parcel.rename(columns={'name10': 'place_name_2010'}, inplace=True)\n",
    "# gdf_parcel.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "gdf = load_layer(eg_conn, 'place2020', ['name','geometry'])\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf, how=\"left\")\n",
    "gdf_parcel.rename(columns={'name': 'place_name_2020'}, inplace=True)\n",
    "gdf_parcel.drop(columns=['index_right'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_equity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use Elmer tables to get the equity geography data\n",
    "e_conn = psrcelmerpy.ElmerConn()\n",
    "\n",
    "# See this for reference http://aws-linux/mediawiki/index.php/Equity_Geographies_in_Elmer\n",
    "df_equity = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.racial_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df_equity.rename(columns={'equity_geog_vs_50_percent': 'racial_geog_vs_50_percent',\n",
    "                          'equity_geog_vs_reg_total': 'racial_geog_vs_reg_total'},\n",
    "                          inplace=True)\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.disability_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'disability_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'disability_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.elderly_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'elderly_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'elderly_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.limited_english_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'english_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'english_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.poverty_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'poverty_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'poverty_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')\n",
    "\n",
    "df = e_conn.get_query(\"select geoid, equity_geog_vs_50_percent, equity_geog_vs_reg_total from census.youth_equity_geographies(\"+equity_data_year+\", 'Tract')\")\n",
    "df.rename(columns={'equity_geog_vs_50_percent': 'youth_geog_vs_50_percent',\n",
    "                   'equity_geog_vs_reg_total': 'youth_geog_vs_reg_total'},\n",
    "                   inplace=True)\n",
    "df_equity = df_equity.merge(df, on='geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to geodataframe\n",
    "# Note, per ACS the geography should correspond with the latest data in ACS 3- or 5-year data (or the given year of 1-year ACS).\n",
    "# This means we will use 2020 geography for 5-year ACS data from 2017-2022, which is listed as 2022 data in Elmer for the tract equity data \n",
    "# https://www.census.gov/programs-surveys/acs/geography-acs/geography-boundaries-by-year.2022.html\n",
    "\n",
    "# join to geodataframe basedon tract\n",
    "if int(equity_data_year) >= 2020:\n",
    "    gdf_col = 'Census2020Tract'\n",
    "else:\n",
    "    gdf_col = 'Census2010Tract'\n",
    "\n",
    "gdf_parcel = gdf_parcel.merge(df_equity, left_on=gdf_col, right_on='geoid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "gdf_parcel.rename(columns={'PARCEL_ID': 'ParcelID'}, inplace=True)\n",
    "gdf_parcel['BaseYear'] = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifically label parcels outside of RGCs\n",
    "gdf_parcel['GrowthCenterName'] = gdf_parcel['GrowthCenterName'].fillna('Not in RGC')\n",
    "\n",
    "# Rename parcel ID to match convention\n",
    "gdf_parcel.rename(columns={'parcelid': 'ParcelID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename counties that are outside the region\n",
    "gdf_parcel.loc[~gdf_parcel['CountyName'].isin(['King','Kitsap','Pierce','Snohomish']), 'CountyName'] = 'Outside Region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HCT station data provided by Craig\n",
    "gdf_stops = gpd.read_file(r'R:\\e2projects_two\\2023_base_year\\network\\transit_stops.shp')\n",
    "gdf_stops.rename(columns={'all_day': 'all_day_transit',\n",
    "                          'frequent': 'frequent_transit',\n",
    "                          'min_routes': 'min_transit'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>frequent_transit</th>\n",
       "      <th>all_day_transit</th>\n",
       "      <th>min_transit</th>\n",
       "      <th>hct</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ct_1</td>\n",
       "      <td>Marine Dr NE &amp; 27th Ave NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1308628.035 388068.676, 1308626.226 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ct_7</td>\n",
       "      <td>Marine Dr NE &amp; 23rd Ave NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1307297.752 387728.165, 1307295.943 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ct_12</td>\n",
       "      <td>Totem Beach Rd &amp; Tulalip Bay Dr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1288816.444 390279.579, 1288814.635 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ct_13</td>\n",
       "      <td>Totem Beach Rd &amp; 70th St NW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1289288.480 389692.453, 1289286.671 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ct_18</td>\n",
       "      <td>Marine Dr NE &amp; 19th Ave NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((1306231.570 387167.052, 1306229.761 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stop_id                        stop_name  frequent_transit  all_day_transit  \\\n",
       "0    ct_1       Marine Dr NE & 27th Ave NE               0.0              0.0   \n",
       "1    ct_7       Marine Dr NE & 23rd Ave NE               0.0              0.0   \n",
       "2   ct_12  Totem Beach Rd & Tulalip Bay Dr               0.0              0.0   \n",
       "3   ct_13      Totem Beach Rd & 70th St NW               0.0              0.0   \n",
       "4   ct_18       Marine Dr NE & 19th Ave NE               0.0              0.0   \n",
       "\n",
       "   min_transit  hct                                           geometry  \n",
       "0          0.0  0.0  POLYGON ((1308628.035 388068.676, 1308626.226 ...  \n",
       "1          0.0  0.0  POLYGON ((1307297.752 387728.165, 1307295.943 ...  \n",
       "2          0.0  0.0  POLYGON ((1288816.444 390279.579, 1288814.635 ...  \n",
       "3          0.0  0.0  POLYGON ((1289288.480 389692.453, 1289286.671 ...  \n",
       "4          0.0  0.0  POLYGON ((1306231.570 387167.052, 1306229.761 ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_stops.head()\n",
    "# FIXME: make sure the geography matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all_day = gdf_stops[gdf_stops['all_day_transit']==1][['all_day_transit','geometry']]\n",
    "gdf_frequent = gdf_stops[gdf_stops['frequent_transit']==1][['frequent_transit','geometry']]\n",
    "gdf_hct = gdf_stops[gdf_stops['hct']==1][['hct','geometry']]\n",
    "gdf_min = gdf_stops[gdf_stops['min_transit']==1][['min_transit','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gdf_min'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Modeller\\AppData\\Local\\anaconda3\\envs\\summary\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gdf_min'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b6db6d7dd0da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mgdf_parcel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf_parcel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgdf_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"left\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mgdf_parcel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index_right'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mgdf_parcel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gdf_min'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mgdf_parcel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Modeller\\AppData\\Local\\anaconda3\\envs\\summary\\lib\\site-packages\\geopandas\\geodataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \u001b[0mGeoDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \"\"\"\n\u001b[1;32m-> 1327\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m         \u001b[0mgeo_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_geometry_column_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGeometryDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Modeller\\AppData\\Local\\anaconda3\\envs\\summary\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Modeller\\AppData\\Local\\anaconda3\\envs\\summary\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gdf_min'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Merge spatially join each to parcel data\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf_all_day, how=\"left\")\n",
    "gdf_parcel.drop('index_right', axis=1, inplace=True)\n",
    "gdf_parcel['all_day_transit'].fillna(0, inplace=True)\n",
    "gdf_parcel.drop_duplicates(inplace=True)\n",
    "\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf_frequent, how=\"left\")\n",
    "gdf_parcel.drop('index_right', axis=1, inplace=True)\n",
    "gdf_parcel['frequent_transit'].fillna(0, inplace=True)\n",
    "gdf_parcel.drop_duplicates(inplace=True)\n",
    "\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf_hct, how=\"left\")\n",
    "gdf_parcel.drop('index_right', axis=1, inplace=True)\n",
    "gdf_parcel['hct'].fillna(0, inplace=True)\n",
    "gdf_parcel.drop_duplicates(inplace=True)\n",
    "\n",
    "gdf_parcel = gpd.sjoin(gdf_parcel, gdf_min, how=\"left\")\n",
    "gdf_parcel.drop('index_right', axis=1, inplace=True)\n",
    "gdf_parcel['min_transit'].fillna(0, inplace=True)\n",
    "gdf_parcel.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_parcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel.drop(['geoid','taz_p'], axis=1, inplace=True)\n",
    "\n",
    "# Set some fields as integers\n",
    "col_list = ['TAZ','District','racial_geog_vs_50_percent', 'racial_geog_vs_reg_total',\n",
    "       'disability_geog_vs_50_percent', 'disability_geog_vs_reg_total',\n",
    "       'elderly_geog_vs_50_percent', 'elderly_geog_vs_reg_total',\n",
    "       'english_geog_vs_50_percent', 'english_geog_vs_reg_total',\n",
    "       'poverty_geog_vs_50_percent', 'poverty_geog_vs_reg_total',\n",
    "       'youth_geog_vs_50_percent', 'youth_geog_vs_reg_total',\n",
    "       'all_day_transit','frequent_transit','hct','min_transit']\n",
    "gdf_parcel[col_list] = gdf_parcel[col_list].fillna(-1).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329928"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf_parcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_parcel.to_csv(r'C:\\Workspace\\parcel_2023_geography.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_parcel = pd.read_csv(r'C:\\Workspace\\parcel_2023_geography.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1268116\n",
       "1      61812\n",
       "Name: hct, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gdf_parcel['hct'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
