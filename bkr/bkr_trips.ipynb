{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert trip records into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from input_configuration import *\n",
    "from scripts.EmmeProject import *\n",
    "from scripts.skimming.SkimsAndPaths import *\n",
    "sys.path.append(os.path.join(os.getcwd(),\"inputs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# USER CLASSES DEFINED PER BELLEVUE'S 3 CLASSES\n",
    "matrix_dict = json_to_dictionary(\"bkr_user_classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store in an h5 file\n",
    "# all matrices must be stored in a \"data\" table to be read by emme\n",
    "# trips.h5 -> data -> [sov,hov,transit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read trip records\n",
    "daysim_outputs_loc = r'R:\\SoundCast\\releases\\TransportationFutures2010\\outputs\\daysim_outputs.h5'\n",
    "my_store = h5py.File(daysim_outputs_loc, \"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the Matrix File from the Dictionary File and Set Unique Matrix Names\n",
    "matrix_dict = text_to_dictionary('demand_matrix_dictionary')\n",
    "uniqueMatrices = set(matrix_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stores in the HDF5 Container to read or write to\n",
    "daysim_set = my_store['Trip']\n",
    "\n",
    "# Select only trips departing between specified time period\n",
    "# Between 5-6 pm\n",
    "tod = 17\n",
    "\n",
    "# Get the index for trips in TOD to only loop over those\n",
    "deptm = np.asarray(daysim_set[\"deptm\"])\n",
    "\n",
    "df_deptm = pd.DataFrame(deptm/60,columns=['dephr'])\n",
    "df_deptm['index_col'] = df_deptm.index\n",
    "\n",
    "tod_index = df_deptm[df_deptm['dephr']==tod]['index_col'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114904"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tod_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15397776"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deptm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "851101/15397776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method File.close of <HDF5 file \"daysim_outputs.h5\" (mode r+)>>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opcl = np.asarray(daysim_set[\"opcl\"])\n",
    "opcl = opcl.astype('int')\n",
    "\n",
    "\n",
    "dpcl = np.asarray(daysim_set[\"dpcl\"])\n",
    "dpcl = dpcl.astype('int')\n",
    "\n",
    "\n",
    "mode = np.asarray(daysim_set[\"mode\"])\n",
    "mode = mode.astype(\"int\")\n",
    "\n",
    "trexpfac = np.asarray(daysim_set[\"trexpfac\"])\n",
    "\n",
    "if not survey_seed_trips:\n",
    "    vot = np.asarray(daysim_set[\"vot\"])\n",
    "\n",
    "dorp = np.asarray(daysim_set[\"dorp\"])\n",
    "dorp = dorp.astype('int')\n",
    "\n",
    "\n",
    "toll_path = np.asarray(daysim_set[\"pathtype\"])\n",
    "toll_path = toll_path.astype('int')\n",
    "\n",
    "my_store.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the BKR zone lookup for parcels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using internal BKR zones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bkr_lookup = pd.read_csv(r'D:/bkr/bkrtaz_internal_parcels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bkr_lookup = bkr_lookup[['TAZNUM','PARCELID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove any duplicate rows, keeping the first occurance\n",
    "# not sure why there are duplicates, but there are only ~ 50 out of 1176991\n",
    "bkr_lookup.drop_duplicates(subset='PARCELID',keep='first',inplace=True)\n",
    "\n",
    "# # Get zone numbers\n",
    "bkr_zones = bkr_lookup.groupby('TAZNUM').count().index.tolist()\n",
    "\n",
    "# add an extra zone to place the umatched parcels\n",
    "##### Zone \n",
    "bkr_zones.append(bkr_zones[-1]+1)\n",
    "\n",
    "dictZoneLookup = dict((value,index) for index,value in enumerate(bkr_zones))\n",
    "\n",
    "zonesDim = len(dictZoneLookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join origin and destination parcel to BKR TAZ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create otaz and dtaz arrays that contain BKR o and d taz definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opcl_df = pd.DataFrame(opcl,columns=['opcl'])\n",
    "df = opcl_df.merge(bkr_lookup,left_on='opcl',right_on='PARCELID',how='left')\n",
    "\n",
    "# Fill NaN rows with the fake BKR zone\n",
    "df.fillna(bkr_zones[-1],inplace=True)\n",
    "\n",
    "otaz = df['TAZNUM'].as_matrix()\n",
    "del df, opcl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dpcl_df = pd.DataFrame(dpcl,columns=['dpcl'])\n",
    "df = dpcl_df.merge(bkr_lookup,left_on='dpcl',right_on='PARCELID',how='left')\n",
    "\n",
    "# Fill NaN rows with the fake BKR zone\n",
    "df.fillna(bkr_zones[-1],inplace=True)\n",
    "\n",
    "dtaz = df['TAZNUM'].as_matrix()\n",
    "del df, dpcl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:33: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Use daysim trips here\n",
    "survey_seed_trips = False\n",
    "\n",
    "#create & store in-memory numpy matrices in a dictionary. Key is matrix name, value is the matrix\n",
    "#also load up the external and truck trips\n",
    "demand_matrices={}\n",
    "\n",
    "for matrix in list(uniqueMatrices):\n",
    "    if matrix not in demand_matrices.keys():\n",
    "        demand_matrix = np.zeros((bkr_zones[-1],bkr_zones[-1]), np.float16)\n",
    "        demand_matrices.update({matrix : demand_matrix})\n",
    "        \n",
    "unprocessed = 0\n",
    "processed = 0\n",
    "# for x in range (0, len(otaz)):\n",
    "for x in tod_index:\n",
    "\n",
    "    processed += 1\n",
    "    if vot[x] < 15: vot[x]=1\n",
    "    elif vot[x] < 25: vot[x]=2\n",
    "    else: vot[x]=3\n",
    "\n",
    "    #get the matrix name from matrix_dict. Throw out school bus (8) for now.\n",
    "    if mode[x] <= 0: \n",
    "         print x, mode[x]\n",
    "    if mode[x]<8:\n",
    "        #Only want drivers, transit trips.\n",
    "        if dorp[x] <= 1:\n",
    "            mat_name = matrix_dict[(int(mode[x]),int(vot[x]),int(toll_path[x]))]\n",
    "            myOtaz = otaz[x]-1\n",
    "            myDtaz = dtaz[x]-1\n",
    "\n",
    "            demand_matrices[mat_name][myOtaz, myDtaz] = demand_matrices[mat_name][myOtaz, myDtaz] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       1,        9,       10, ..., 15397733, 15397741, 15397764], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tod_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9\n",
      "10\n",
      "15\n",
      "30\n",
      "35\n",
      "37\n",
      "89\n",
      "117\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "for x in tod_index[:10]:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56032.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_matrices['svnt1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## Now we have matrices in memory\n",
    "# svnt1 has infinite values...\n",
    "# IGNORE svnt1 for now?\n",
    "# Aggregate to fit BKR needs\n",
    "sov =  demand_matrices['svnt1']+demand_matrices['svnt2']+demand_matrices['svnt3']+\\\n",
    "    demand_matrices['svtl1']+demand_matrices['svtl2']+demand_matrices['svtl3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hov2 =  demand_matrices['h2nt1']+demand_matrices['h2nt2']+demand_matrices['h2nt3']+\\\n",
    "    demand_matrices['h2tl1']+demand_matrices['h2tl2']+demand_matrices['h2tl3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hov3 =  demand_matrices['h3nt1']+demand_matrices['h3nt2']+demand_matrices['h3nt3']+\\\n",
    "    demand_matrices['h3tl1']+demand_matrices['h3tl2']+demand_matrices['h3tl3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sov)\n",
    "# df.columns = dictZoneLookup.keys()\n",
    "# df.index = dictZoneLookup.keys()\n",
    "df.columns = range(1,bkr_zones[-1]+1)\n",
    "df.index = range(1,bkr_zones[-1]+1)\n",
    "df.to_csv('sov.csv')\n",
    "\n",
    "# # totals by P&A\n",
    "df = pd.DataFrame([df.sum(axis=0),df.sum(axis=1)]).T\n",
    "df.columns = ['prd','attr']\n",
    "df.to_csv('sov_p_a.csv',index_label='taz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hov2)\n",
    "df.columns = range(1,bkr_zones[-1]+1)\n",
    "df.index = range(1,bkr_zones[-1]+1)\n",
    "df.to_csv('hov2.csv')\n",
    "\n",
    "df = pd.DataFrame([df.sum(axis=0),df.sum(axis=1)]).T\n",
    "df.columns = ['prd','attr']\n",
    "df.to_csv('hov2_p_a.csv',index_label='taz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hov3)\n",
    "df.columns = range(1,bkr_zones[-1]+1)\n",
    "df.index = range(1,bkr_zones[-1]+1)\n",
    "df.to_csv('hov3.csv')\n",
    "\n",
    "df = pd.DataFrame([df.sum(axis=0),df.sum(axis=1)]).T\n",
    "df.columns = ['prd','attr']\n",
    "df.to_csv('hov3_p_a.csv',index_label='taz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get origin and destination totals to compare vs soundcast zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total SOV Trips from this notebook\n",
    "# 4304750\n",
    "\n",
    "# compared to all-day soundcast run\n",
    "# sov is mode 3\n",
    "# daysim reports these as \n",
    "# 7076788\n",
    "\n",
    "# still only getting about half of the trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allmode = pd.DataFrame(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7076788"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allmode[allmode[0] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15397776"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
